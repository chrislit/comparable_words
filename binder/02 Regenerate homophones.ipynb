{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homophones\n",
    "\n",
    "#### Set-up and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import urllib.request\n",
    "from itertools import combinations\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('temp')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "if os.path.isfile('./realwords.txt'):\n",
    "    with open('./realwords.txt') as rw_file:\n",
    "        realwords = {_.strip() for _ in rw_file.readlines()}\n",
    "else:\n",
    "    realwords = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "banned_pairs = {\n",
    "    'nickel,nickle',\n",
    "}\n",
    "banned_pairs = {tuple(pair.split(',')) for pair in banned_pairs}\n",
    "for fn in ['cognates', 'cognates_maxlen12']:\n",
    "    with open(f'../{fn}.csv') as fh:\n",
    "        banned_pairs |= {tuple(pair.strip().split(',')) for pair in fh.readlines()[1:]}\n",
    "banned_pairs |= {(_[1], _[0]) for _ in banned_pairs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_sets = {\n",
    "    (\"a while\",\"awhile\"),\n",
    "    (\"all ready\",\"already\"),\n",
    "    (\"all together\",\"altogether\"),\n",
    "    (\"androgenous\",\"androgynous\"),\n",
    "    (\"barer\",\"bearer\"),\n",
    "    (\"baring\",\"bearing\"),\n",
    "    (\"baroness\",\"barrenness\"),\n",
    "    (\"basks\",\"Basques\"),\n",
    "    (\"batsman\",\"batsmen\"),\n",
    "    (\"broom\",\"brume\"),\n",
    "    (\"cannonry\",\"canonry\"),\n",
    "    (\"cavalryman\",\"cavalrymen\"),\n",
    "    (\"cays\",\"quays\"),\n",
    "    (\"coaming\",\"combing\"),\n",
    "    (\"coarser\",\"courser\"),\n",
    "    (\"coif\",\"quaff\"),\n",
    "    (\"courier\",\"currier\"),\n",
    "    (\"crappie\",\"crappy\"),\n",
    "    (\"crew\",\"krewe\"),\n",
    "    (\"cued\",\"queued\"),\n",
    "    (\"cueing\",\"queueing\"),\n",
    "    (\"cuer\",\"queuer\"),\n",
    "    (\"deal\",\"dele\"),\n",
    "    (\"depravation\",\"deprivation\"),\n",
    "    (\"dies\",\"dyes\"),\n",
    "    (\"eaves\",\"eves\"),\n",
    "    (\"entrance\",\"entrants\"),\n",
    "    (\"envoi\",\"envoy\"),\n",
    "    (\"fainted\",\"feinted\"),\n",
    "    (\"fainting\",\"feinting\"),\n",
    "    (\"faints\",\"feints\"),\n",
    "    (\"fairs\",\"fares\"),\n",
    "    (\"fakers\",\"fakirs\"),\n",
    "    (\"fates\",\"fetes\"),\n",
    "    (\"faux\",\"foe\"),\n",
    "    (\"filets\",\"fillets\"),\n",
    "    (\"flay\",\"fley\"),\n",
    "    (\"fleas\",\"flees\"),\n",
    "    (\"fliers\",\"flyers\"),\n",
    "    (\"florescence\",\"fluorescents\"),\n",
    "    (\"floured\",\"flowered\"),\n",
    "    (\"flours\",\"flowers\"),\n",
    "    (\"fluorescence\",\"fluorescents\"),\n",
    "    (\"foreward\",\"foreword\"),\n",
    "    (\"gaol\",\"jail\"),\n",
    "    (\"gnatty\",\"natty\"),\n",
    "    (\"hippie\",\"hippy\"),\n",
    "    (\"ileum\",\"ilium\"),\n",
    "    (\"lade\",\"layed\"),\n",
    "    (\"laid\",\"layed\"),\n",
    "    (\"lamas\",\"llamas\"),\n",
    "    (\"lead\",\"lede\"),\n",
    "    (\"lies\",\"lyes\"),\n",
    "    (\"lies\",\"lyse\"),\n",
    "    (\"light\",\"lite\"),\n",
    "    (\"lyes\",\"lyse\"),\n",
    "    (\"may be\",\"maybe\"),\n",
    "    (\"murre\",\"myrrh\"),\n",
    "    (\"overbilled\",\"overbuild\"),\n",
    "    (\"paeon\",\"peon\"),\n",
    "    (\"peaking\",\"peeking\"),\n",
    "    (\"poling\",\"polling\"),\n",
    "    (\"psi\",\"scye\"),\n",
    "    (\"raining\",\"reigning\"),\n",
    "    (\"raining\",\"reining\"),\n",
    "    (\"raise\",\"res\"),\n",
    "    (\"raising\",\"rasing\"),\n",
    "    (\"raising\",\"razing\"),\n",
    "    (\"rase\",\"res\"),\n",
    "    (\"rasing\",\"razing\"),\n",
    "    (\"rays\",\"res\"),\n",
    "    (\"raze\",\"res\"),\n",
    "    (\"reave\",\"rive\"),\n",
    "    (\"receipted\",\"reseated\"),\n",
    "    (\"receipts\",\"reseats\"),\n",
    "    (\"reeve\",\"rive\"),\n",
    "    (\"reigning\",\"reining\"),\n",
    "    (\"righting\",\"writing\"),\n",
    "    (\"said\",\"sed\"),\n",
    "    (\"sailer\",\"sailor\"),\n",
    "    (\"sain\",\"sane\"),\n",
    "    (\"sain\",\"seine\"),\n",
    "    (\"scold\",\"skald\"),\n",
    "    (\"she\",\"sidhe\"),\n",
    "    (\"shea\",\"sidhe\"),\n",
    "    (\"shivaree\",\"shivery\"),\n",
    "    (\"soccer\",\"socker\"),\n",
    "    (\"sodder\",\"solder\"),\n",
    "    (\"spear\",\"speer\"),\n",
    "    (\"speel\",\"spiel\"),\n",
    "    (\"spier\",\"spire\"),\n",
    "    (\"steals\",\"steels\"),\n",
    "    (\"steals\",\"steles\"),\n",
    "    (\"steels\",\"steles\"),\n",
    "    (\"stolen\",\"stollen\"),\n",
    "    (\"talkie\",\"talky\"),\n",
    "    (\"taro\",\"tarot\"),\n",
    "    (\"teared\",\"tiered\"),\n",
    "    (\"tenuis\",\"tenuous\"),\n",
    "    (\"tore\",\"torr\"),\n",
    "    (\"vices\",\"vises\"),\n",
    "    (\"wailed\",\"whaled\"),\n",
    "    (\"wails\",\"whales\"),\n",
    "    (\"waiting\",\"weighting\"),\n",
    "    (\"watt\",\"wot\"),\n",
    "    (\"what\",\"wot\"),\n",
    "    (\"whiny\",\"winy\"),\n",
    "    (\"why'd\",\"wide\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grab basis dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not os.path.isfile(os.path.join('temp', 'homophone_list.csv')) or\n",
    "    not os.path.isfile(os.path.join('temp', 'homophones.php'))):\n",
    "    urls = [\n",
    "        'https://raw.githubusercontent.com/TSMMark/homophone/master/lib/assets/homophone_list.csv',\n",
    "        'http://members.peak.org/~jeremy/dictionaryclassic/chapters/homophones.php',\n",
    "    ]\n",
    "    for url in urls:\n",
    "        urllib.request.urlretrieve(url, os.path.join('temp', url.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('temp', 'homophone_list.csv'))\n",
    "df = df.iloc[:,-2:]\n",
    "df = df.to_dict('records')\n",
    "\n",
    "extr = {}\n",
    "for rec in df:\n",
    "    w = rec['spelling']\n",
    "    n = rec['relation_id']\n",
    "    if n not in extr:\n",
    "        extr[n] = set()\n",
    "    extr[n].add(w)\n",
    "\n",
    "homophones = []\n",
    "for rec in extr.values():\n",
    "    homophones += combinations(rec, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('temp', 'homophones.php')) as file:\n",
    "    wordlist = file.read()\n",
    "\n",
    "wordlist = wordlist[wordlist.find('<pre>')+5:wordlist.find('</pre>')].strip().split('\\n')\n",
    "wordlist = [_.split(',') for _ in wordlist]\n",
    "\n",
    "for words in wordlist:\n",
    "    words = [_.strip() for _ in words]\n",
    "    homophones += combinations(words, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.singularis.ltd.uk/bifroest/misc/homophones-list.html'\n",
    "res = requests.get(url, headers={'Cache-Control': 'no-cache'})\n",
    "soup = BeautifulSoup(res.content,'lxml')\n",
    "lis = soup.find_all('li')\n",
    "\n",
    "for words in lis:\n",
    "    words = [_.strip() for _ in words.get_text().split(',')]\n",
    "    homophones += combinations(words, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophones += sorted(additional_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophones = sorted(set(homophones)-banned_pairs)\n",
    "homophones = sorted(set(tuple(sorted(_)) for _ in homophones if _[0].lower()!=_[1].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word1, word2 in homophones:\n",
    "    realwords.add(word1)\n",
    "    realwords.add(word2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomly select from the misspellings and write output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(pair):\n",
    "    return pair[::-1] if random.choice((True, False)) else pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2345)\n",
    "\n",
    "homophones1 = sorted([reorder(_) for _ in homophones])\n",
    "random.shuffle(homophones1)\n",
    "rev_homophones = [pair[::-1] for pair in homophones1]\n",
    "random.shuffle(rev_homophones)\n",
    "homophones1 += rev_homophones\n",
    "\n",
    "with open('../homophones.csv', 'w') as file:\n",
    "    file.write('word1,word2\\n')\n",
    "    rev_val = True\n",
    "    for pair in homophones1[:2400]:\n",
    "        file.write(','.join(reorder(pair))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(437)\n",
    "\n",
    "homophones2 = []\n",
    "for a,b in sorted([reorder(_) for _ in homophones]):\n",
    "    if len(a) < 13 and len(b) < 13:\n",
    "        homophones2.append((a,b))\n",
    "random.shuffle(homophones2)\n",
    "rev_homophones = [pair[::-1] for pair in homophones2]\n",
    "random.shuffle(rev_homophones)\n",
    "homophones2 += rev_homophones\n",
    "\n",
    "with open('../homophones_maxlen12.csv', 'w') as file:\n",
    "    file.write('word1,word2\\n')\n",
    "    rev_val = True\n",
    "    for pair in homophones2[:2400]:\n",
    "        file.write(','.join(reorder(pair))+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save our realwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "realwords = sorted(realwords)\n",
    "with open('./realwords.txt', 'w') as rw_file:\n",
    "    for word in realwords:\n",
    "        rw_file.write(word+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
