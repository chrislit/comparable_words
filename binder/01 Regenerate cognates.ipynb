{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cognates\n",
    "\n",
    "#### Set-up and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import urllib.request\n",
    "from itertools import combinations\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tabula import read_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('temp')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "if os.path.isfile('./realwords.txt'):\n",
    "    with open('./realwords.txt') as rw_file:\n",
    "        realwords = {_.strip() for _ in rw_file.readlines()}\n",
    "else:\n",
    "    realwords = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German\n",
    "#### Gather German cognates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wiktionary.org/wiki/Appendix:List_of_German_cognates_with_English#Borrowings_into_Old_German_and_Old_English\"\n",
    "\n",
    "res = requests.get(url, headers={'Cache-Control': 'no-cache'})\n",
    "soup = BeautifulSoup(res.content,'lxml')\n",
    "table = soup.find_all('table')\n",
    "df = pd.read_html(str(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_cognates = []\n",
    "for frame in df:\n",
    "    for n in range(1, frame.shape[0]):\n",
    "        row = frame.iloc[n]\n",
    "        de_cognates.append((row[0], row[1]))\n",
    "\n",
    "def clean_de_cognates(cognates):\n",
    "    cognates = sorted(set(cognates))\n",
    "\n",
    "    new_cognates = []\n",
    "    for german, english in cognates:\n",
    "        if ';' in german and ';' in english:\n",
    "            german_l = [_.strip() for _ in german.split(';')]\n",
    "            english_l = [_.strip() for _ in english.split(';')]\n",
    "            if len(german_l) == len(english_l):\n",
    "                new_cognates += zip(german_l, english_l)\n",
    "            else:\n",
    "                print(german_l, english_l)\n",
    "                new_cognates.append((german, english))\n",
    "        else:\n",
    "            new_cognates.append((german, english))\n",
    "    cognates = sorted(set(new_cognates))\n",
    "\n",
    "    new_cognates = []\n",
    "    for german, english in cognates:\n",
    "        if '/' in german or '/' in english:\n",
    "            german = german.split('/')\n",
    "            english = english.split('/')\n",
    "            for g in german:\n",
    "                for e in english:\n",
    "                    new_cognates.append((g.strip(), e.strip()))\n",
    "        else:\n",
    "            new_cognates.append((german, english))\n",
    "    cognates = sorted(set(new_cognates))\n",
    "    \n",
    "    new_cognates = []\n",
    "    for german, english in cognates:\n",
    "        if (re.findall(r'(^|[a-zA-Z]+)\\(.+?\\)', german) or re.findall(r'(^|[a-zA-Z]+)\\(.+?\\)', english)):\n",
    "\n",
    "            extra_german = re.sub(r'\\(.+?\\)', '', german).strip()\n",
    "            extra_english = re.sub(r'\\(.+?\\)', '', english).strip()\n",
    "            for g in (german, extra_german):\n",
    "                for e in (english, extra_english):\n",
    "                    new_cognates.append((g, e))\n",
    "        else:\n",
    "            new_cognates.append((german, english))\n",
    "    cognates = sorted(set(new_cognates))\n",
    "    \n",
    "    for i, pair in enumerate(cognates):\n",
    "        german, english = pair\n",
    "\n",
    "        for char in ';,':\n",
    "            german = re.sub(char+'.*', '', german)\n",
    "            english = re.sub(char+'.*', '', english)\n",
    "\n",
    "        german = re.sub(r'\\[.+?\\]', '', german)\n",
    "        english = re.sub(r'\\[.+?\\]', '', english)\n",
    "\n",
    "        german = re.sub(r' \\(.+', '', german)\n",
    "        english = re.sub(r' \\(.+', '', english)\n",
    "        german = re.sub(r' \\[.+', '', german)\n",
    "        english = re.sub(r' \\[.+', '', english)\n",
    "\n",
    "        german = german.replace('*', '')\n",
    "        english = english.replace('*', '')\n",
    "\n",
    "        for char in '()':\n",
    "            german = german.replace(char, '')\n",
    "            english = english.replace(char, '')\n",
    "\n",
    "        cognates[i] = german.strip(), english.strip()\n",
    "\n",
    "        if not re.findall('[A-Za-z]', german) or not re.findall('[A-Za-z]', english):\n",
    "            cognates[i] = ('',)\n",
    "\n",
    "    cognates = sorted(set(cognates))\n",
    "    if ('',) in cognates:\n",
    "        cognates.remove(('',))\n",
    "    return cognates\n",
    "\n",
    "de_cognates = clean_de_cognates(de_cognates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save our German cognates & realwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp/de_cognates.csv', 'w') as file:\n",
    "    file.write('german,english\\n')\n",
    "    for de,en in de_cognates:\n",
    "        file.write(f'{de},{en}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "realwords = sorted(realwords | {_[1] for _ in de_cognates})\n",
    "with open('./realwords.txt', 'w') as rw_file:\n",
    "    for word in sorted(realwords):\n",
    "        rw_file.write(word+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### French\n",
    "#### Gather French cognates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('temp/GlossaryCognatesFrenchUpdated5-5-2014.pdf',\n",
       " <http.client.HTTPMessage at 0x7fcfd37e89e8>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://steinhardt.nyu.edu/scmsAdmin/media/users/xr1/glossaries/ELA/GlossaryCognatesFrenchUpdated5-5-2014.pdf'\n",
    "urllib.request.urlretrieve(url, os.path.join('temp', url.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual corrections from Google Translate, based on the symmetric difference to the sets of cognates\n",
    "drop_french = {'vote', 'volley-ball', 'trumpet', 'tourist', 'splendid', 'reméde', 'problem', 'plant',\n",
    "               'opèrer', 'objèt', 'music', 'magnetic', 'magician', 'lígne', 'lens', 'incrédíble', 'general',\n",
    "               'gas', 'fantstique', 'egoïste', 'electricity', 'comentaire', 'brilliant-te', 'authorize',\n",
    "               'astronomer', 'artístique', 'aggrégat', 'Idée', 'Different-e', 'special-e', 'medaille',\n",
    "               'inmédiatement',\n",
    "}\n",
    "drop_english = {'statistics', 'effective', 'Study'}\n",
    "swap_french = {'prudent', 'study', 'honor', 'electric'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_pdf(os.path.join('temp', url.split('/')[-1]), pages='4-25', pandas_options={'header': None})\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['participate']\n",
      "['participate']\n"
     ]
    }
   ],
   "source": [
    "lines = [' '.join(str(__) for __ in _).strip() for _ in df.get_values()]\n",
    "fr_cognates = []\n",
    "cog = []\n",
    "for line in lines:\n",
    "    if 'English' in line or 'French' in line:\n",
    "        continue\n",
    "    line = line.split(' ')\n",
    "    if len(cog) == 2:\n",
    "        cog = []\n",
    "    for word in line:\n",
    "        if word in {'', '(to)', '(se)'}:\n",
    "            continue\n",
    "        for part in '0123456789':\n",
    "            word = word.replace(part, '')\n",
    "        for part in ['(to)', '(se)']:\n",
    "            word = word.replace(part, '')\n",
    "        if word:\n",
    "            cog.append(word)\n",
    "    if cog:\n",
    "        if len(cog) == 3:\n",
    "            cog = [cog[0]+cog[1], cog[2]]\n",
    "        if len(cog) != 2:\n",
    "            print(cog)\n",
    "        else:\n",
    "            cog = cog[::-1]\n",
    "            if cog[0] not in drop_french and cog[1] not in drop_english:\n",
    "                if cog[0] in swap_french:\n",
    "                    cog = cog[::-1]\n",
    "                fr_cognates.append(tuple(cog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_pdf(os.path.join('temp', url.split('/')[-1]), pages='27-48', pandas_options={'header': None})\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['banjo']\n",
      "['banjo']\n",
      "['pionnier']\n",
      "['pionnier']\n"
     ]
    }
   ],
   "source": [
    "lines = [' '.join(str(__) for __ in _).strip() for _ in df.get_values()]\n",
    "fr_cognates2 = []\n",
    "cog = []\n",
    "for line in lines:\n",
    "    if 'English' in line or 'French' in line:\n",
    "        continue\n",
    "    line = line.split(' ')\n",
    "    if len(cog) == 2:\n",
    "        cog = []\n",
    "    for word in line:\n",
    "        if word in {'', '(to)', '(se)'}:\n",
    "            continue\n",
    "        for part in '0123456789':\n",
    "            word = word.replace(part, '')\n",
    "        for part in ['(to)', '(se)']:\n",
    "            word = word.replace(part, '')\n",
    "        if word:\n",
    "            cog.append(word)\n",
    "    if cog:\n",
    "        if len(cog) == 3:\n",
    "            cog = [cog[0]+cog[1], cog[2]]\n",
    "        if len(cog) != 2:\n",
    "            print(cog)\n",
    "        else:\n",
    "            if cog[0] not in drop_french and cog[1] not in drop_english:\n",
    "                if cog[0] in swap_french:\n",
    "                    cog = cog[::-1]\n",
    "                fr_cognates2.append(tuple(cog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_cognates = sorted(set(fr_cognates) | set(fr_cognates2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_cognates2 = []\n",
    "for fr, en in fr_cognates:\n",
    "    if '-' not in fr:\n",
    "        fr_cognates2.append((fr, en))\n",
    "    else:\n",
    "        fr = fr.split('-')\n",
    "        fr_cognates2.append((fr[0], en))\n",
    "        fr_cognates2.append((''.join(fr), en))\n",
    "fr_cognates = sorted(set(fr_cognates2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_cognates = \"\"\"Crown,couronne\n",
    "Custom,coutume\n",
    "Assizes,assises\n",
    "Franchise,franchise\n",
    "Joust,joute\n",
    "Marriage,mariage\n",
    "Parliament,parlement\n",
    "Heir,héritier\n",
    "Chef,chef\n",
    "chief,chef\n",
    "Caterer,approvisionneur\n",
    "Pay,payer\n",
    "Ticket,ticket\n",
    "Purchase,acheter\n",
    "Rental,loyer\n",
    "Debt,dette\n",
    "Affair,affaire\n",
    "Court,cour\n",
    "Aunt,tante\n",
    "Chamber,chambre\n",
    "Chair,chaise\n",
    "Cushion,coussin\n",
    "Cabbage,choux\n",
    "Bacon,bacon\n",
    "Cauldron,chaudron\n",
    "Mustard,moutarde\n",
    "Mutton,mouton\n",
    "Beef,bœuf\n",
    "Pork,porc\n",
    "Poultry,poulet\n",
    "Claret,clairet\n",
    "Mince,émincer\n",
    "Stew,ragoût\n",
    "Veal,veau\n",
    "Banquet,banquet\n",
    "Carrot,carotte\n",
    "Aperitif,apéritif\n",
    "Pony,poney\n",
    "toilet,Toilette\n",
    "Causeway,chaussée\n",
    "Kennel,chenil\n",
    "Solace,consolation\n",
    "Square,carré\n",
    "Change,changer\n",
    "Chapel,chapelle\n",
    "Choice,choix\n",
    "Mischief,méchanceté\n",
    "Achieve,achever\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for line in more_cognates.split('\\n'):\n",
    "    fr, en = line.lower().split(',')\n",
    "    fr_cognates.append((fr, en))\n",
    "fr_cognates = sorted(set(fr_cognates))\n",
    "len(fr_cognates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save our French cognates & realwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp/fr_cognates.csv', 'w') as file:\n",
    "    file.write('french,english\\n')\n",
    "    for fr,en in fr_cognates:\n",
    "        file.write(f'{fr},{en}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "realwords = sorted(set(realwords) | {_[1] for _ in fr_cognates})\n",
    "with open('./realwords.txt', 'w') as rw_file:\n",
    "    for word in sorted(realwords):\n",
    "        rw_file.write(word+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish\n",
    "#### Gather Spanish cognates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.realfastspanish.com/vocabulary/spanish-cognates'\n",
    "res = requests.get(url, headers={'Cache-Control': 'no-cache',\n",
    "                                'User-Agent': 'Mozilla/5.0 (Linux; Android 5.1.1; SM-G928X Build/LMY47X) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.83 Mobile Safari/537.36'})\n",
    "soup = BeautifulSoup(res.content,'lxml')\n",
    "table = soup.find_all('table')\n",
    "df = pd.read_html(str(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_cognates = []\n",
    "for frame in df:\n",
    "    for n in range(1, frame.shape[0]):\n",
    "        row = frame.iloc[n]\n",
    "        es_cognates.append((row[0].lower(), row[1].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('temp/mfcogn.pdf', <http.client.HTTPMessage at 0x7fcfd34c63c8>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://www.cognates.org/pdf/mfcogn.pdf'\n",
    "urllib.request.urlretrieve(url, os.path.join('temp', url.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = read_pdf(os.path.join('temp', url.split('/')[-1]), pages='3-66', pandas_options={'header': None},\n",
    "                  multiple_tables=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3877"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_cognates = []\n",
    "df = frames[0].fillna('').iloc[1:]\n",
    "df[1] = df[1]+' '+df[2]\n",
    "df.drop(2, axis=1, inplace=True)\n",
    "\n",
    "pos = ['prefijo\\.', 'prefix\\.', 'intj\\.', 'prep\\.', 'conj\\.', 'abbr\\.', 'abr\\.', 'adv\\.', 'adj\\.',\n",
    "       'v\\.', 'n\\.', 's\\.']\n",
    "\n",
    "for en, es in df.get_values():\n",
    "    en = en.replace('MFW', '')\n",
    "    es = es.replace('PMF', '')\n",
    "\n",
    "    for p in pos:\n",
    "        en = re.sub(' '+p+'.*', '', en)\n",
    "        es = re.sub(' '+p+'.*', '', es)\n",
    "\n",
    "    en = en.strip()\n",
    "    es = es.strip()\n",
    "    \n",
    "    es_cognates.append((es, en))\n",
    "\n",
    "for df in frames[1:]:\n",
    "    df = df.fillna('')\n",
    "    for _, en, _, es in df.get_values():\n",
    "        for p in pos:\n",
    "            en = re.sub(p+'.*', '', en)\n",
    "            es = re.sub(p+'.*', '', es)\n",
    "\n",
    "        en = en.strip()\n",
    "        es = es.strip()\n",
    "\n",
    "        if ',' in en:\n",
    "            en = en.split(',')\n",
    "            en = ' '.join(en[::-1]).strip()\n",
    "        if ',' in es:\n",
    "            es = es.split(',')\n",
    "            es = ' '.join(es[::-1]).strip()\n",
    "            \n",
    "        es_cognates.append((es, en))\n",
    "\n",
    "es_cognates = sorted(set(es_cognates))\n",
    "len(es_cognates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save our Spanish cognates & realwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp/es_cognates.csv', 'w') as file:\n",
    "    file.write('spanish,english\\n')\n",
    "    for es,en in es_cognates:\n",
    "        file.write(f'{es},{en}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "realwords = sorted(set(realwords) | {_[1] for _ in es_cognates})\n",
    "with open('./realwords.txt', 'w') as rw_file:\n",
    "    for word in sorted(realwords):\n",
    "        rw_file.write(word+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomly select from the misspellings and write output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30408423739629864, 0.6185386088066369, 0.07737715379706446]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = []\n",
    "for ds in [de_cognates, es_cognates, fr_cognates]:\n",
    "    probs.append(len(ds))\n",
    "probs = [pr/sum(probs) for pr in probs]\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(32132)\n",
    "datasets = [list(de_cognates), list(es_cognates), list(fr_cognates)]\n",
    "for i, ds in enumerate(datasets):\n",
    "    datasets[i] = sorted(set(datasets[i]))\n",
    "    random.shuffle(datasets[i])\n",
    "\n",
    "cognates = []\n",
    "pos = 0\n",
    "while len(cognates) < 2400:\n",
    "    for i, ds in enumerate(datasets):\n",
    "        if pos < len(ds):\n",
    "            a,b = ds[pos]\n",
    "            if random.random() > probs[i] and a != b:\n",
    "                cognates.append(ds[pos])\n",
    "    pos += 1\n",
    "\n",
    "with open('../cognates.csv', 'w') as file:\n",
    "    file.write('cognate,english\\n')\n",
    "    for pair in cognates:\n",
    "        file.write(','.join(pair)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(4882)\n",
    "datasets = [list(de_cognates), list(es_cognates), list(fr_cognates)]\n",
    "for i, ds in enumerate(datasets):\n",
    "    ds2 = []\n",
    "    for a,b in sorted(set(datasets[i])):\n",
    "        if len(a) < 13 and len(b) < 13 and a != b:\n",
    "            ds2.append((a,b))\n",
    "    datasets[i] = ds2\n",
    "    random.shuffle(datasets[i])\n",
    "\n",
    "cognates = []\n",
    "pos = 0\n",
    "while len(cognates) < 2400:\n",
    "    for i, ds in enumerate(datasets):\n",
    "        if random.random() > probs[i] and pos < len(ds):\n",
    "            cognates.append(ds[pos])\n",
    "    pos += 1\n",
    "\n",
    "with open('../cognates_maxlen12.csv', 'w') as file:\n",
    "    file.write('cognate,english\\n')\n",
    "    for pair in cognates:\n",
    "        file.write(','.join(pair)+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
