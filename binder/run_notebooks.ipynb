{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regen datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebooks = os.listdir('.')\n",
    "notebooks = sorted(filter(lambda fn: fn.endswith('.ipynb') and fn[:2].isdigit(), notebooks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing notebook 01 Regenerate cognates.ipynb\n",
      "executing notebook 02 Regenerate homophones.ipynb\n",
      "executing notebook 03 Regenerate misspellings.ipynb\n",
      "executing notebook 04 Regenerate surnames variants.ipynb\n",
      "executing notebook 05 Regenerate forename variants.ipynb\n",
      "executing notebook 06 Regenerate typos.ipynb\n",
      "executing notebook 07 Regenerate fake words.ipynb\n",
      "executing notebook 08 Regenerate random English pairs.ipynb\n",
      "executing notebook 09 Regenerate DNA sequences.ipynb\n",
      "executing notebook 10 Regenerate protein sequences.ipynb\n",
      "executing notebook 11 Regenerate inflected verbs.ipynb\n",
      "executing notebook 12 Regenerate Porter2 stemmed.ipynb\n"
     ]
    }
   ],
   "source": [
    "ep = ExecutePreprocessor(timeout=600, kernel_name='python3')\n",
    "\n",
    "for notebook_filename in notebooks:\n",
    "    print(f'executing notebook {notebook_filename}')\n",
    "    with open(notebook_filename) as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "        ep.preprocess(nb, {'metadata': {'path': '.'}})\n",
    "    with open(notebook_filename, 'w', encoding='utf-8') as f:\n",
    "        nbformat.write(nb, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### uniqueness checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 cognates_maxlen12\n",
      "2400 homophones_maxlen12\n",
      "2400 misspellings_maxlen12\n",
      "2400 surnames_maxlen12\n",
      "2400 forenames_maxlen12\n",
      "2400 typos\n",
      "2400 fake_words_maxlen12\n",
      "2400 random_words_maxlen12\n",
      "2400 hg38_maxlen12\n",
      "2400 proteins_len12\n",
      "2400 conjugated_maxlen12\n",
      "2400 porter_maxlen12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28800"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparables = []\n",
    "comp_dict = {}\n",
    "\n",
    "ds = ['cognates_maxlen12', 'homophones_maxlen12', 'misspellings_maxlen12',\n",
    "      'surnames_maxlen12', 'forenames_maxlen12', 'typos',\n",
    "      'fake_words_maxlen12', 'random_words_maxlen12',\n",
    "      'hg38_maxlen12', 'proteins_len12',\n",
    "      'conjugated_maxlen12', 'porter_maxlen12']\n",
    "\n",
    "for fn in ds:\n",
    "    with open(f'../{fn}.csv') as file:\n",
    "        next(file)\n",
    "        lc = 0\n",
    "        comp_dict[fn] = set()\n",
    "        for line in file:\n",
    "            comparables.append(line.strip().lower())\n",
    "            comp_dict[fn].add(line.strip().lower())\n",
    "            lc += 1\n",
    "        print(f'{lc} {fn}')\n",
    "\n",
    "len(set(comparables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cognates_maxlen12 2400\n",
      "homophones_maxlen12 2400\n",
      "misspellings_maxlen12 2400\n",
      "surnames_maxlen12 2400\n",
      "forenames_maxlen12 2400\n",
      "typos 2400\n",
      "fake_words_maxlen12 2400\n",
      "random_words_maxlen12 2400\n",
      "hg38_maxlen12 2400\n",
      "proteins_len12 2400\n",
      "conjugated_maxlen12 2400\n",
      "porter_maxlen12 2400\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "for a,b in combinations(ds, 2):\n",
    "    inter = comp_dict[a] & comp_dict[b]\n",
    "    if inter:\n",
    "        print(a, b, inter)\n",
    "for a in ds:\n",
    "    print(a, len(comp_dict[a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 cognates\n",
      "2400 homophones\n",
      "2400 misspellings\n",
      "2400 surnames\n",
      "2400 forenames\n",
      "2400 typos\n",
      "2400 fake_words\n",
      "2400 random_words\n",
      "2400 hg38\n",
      "2400 proteins\n",
      "2400 conjugated\n",
      "2400 porter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28800"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparables = []\n",
    "comp_dict = {}\n",
    "\n",
    "ds = ['cognates', 'homophones', 'misspellings',\n",
    "      'surnames', 'forenames', 'typos',\n",
    "      'fake_words', 'random_words',\n",
    "      'hg38', 'proteins',\n",
    "      'conjugated', 'porter']\n",
    "\n",
    "for fn in ds:\n",
    "    with open(f'../{fn}.csv') as file:\n",
    "        next(file)\n",
    "        lc = 0\n",
    "        comp_dict[fn] = set()\n",
    "        for line in file:\n",
    "            comparables.append(line.strip().lower())\n",
    "            comp_dict[fn].add(line.strip().lower())\n",
    "            lc += 1\n",
    "        print(f'{lc} {fn}')\n",
    "\n",
    "len(set(comparables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cognates 2400\n",
      "homophones 2400\n",
      "misspellings 2400\n",
      "surnames 2400\n",
      "forenames 2400\n",
      "typos 2400\n",
      "fake_words 2400\n",
      "random_words 2400\n",
      "hg38 2400\n",
      "proteins 2400\n",
      "conjugated 2400\n",
      "porter 2400\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "for a,b in combinations(ds, 2):\n",
    "    inter = comp_dict[a] & comp_dict[b]\n",
    "    if inter:\n",
    "        print(a, b, inter)\n",
    "for a in ds:\n",
    "    print(a, len(comp_dict[a]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
